# User Manual: Network Traffic Classification for QoS Improvement

**Version:** 1.0  
**Author:** Mohammed Aqeel Ismail  
**Institution:** University of KwaZulu-Natal  



## 1. Introduction

### 1.1 What is This System?

This Network Traffic Classification System is a machine learning-based tool that automatically identifies mobile applications from their network traffic patterns and recommends Quality of Service (QoS) policies for optimal network performance.

**Key Benefits:**
- **Privacy-Preserving:** Works without inspecting packet content  
- **High Accuracy:** 89.76% classification accuracy  
- **Automated QoS:** Generates priority, bandwidth, and latency recommendations  
- **Easy to Use:** Simple configuration and execution  

### 1.2 Who Should Use This Manual?  

This manual is designed for:  
- **Researchers** studying network traffic classification  
- **Network Engineers** implementing QoS policies  
- **Students** learning about machine learning in networking  
- **Developers** building traffic management systems  

### 1.3 What You'll Learn

By following this manual, you will:  
1. Install and configure the classification system  
2. Prepare network traffic data for analysis  
3. Train machine learning models on your data  
4. Generate QoS policy recommendations  
5. Evaluate and improve classification accuracy  
6. Deploy trained models in production  

### 1.4 Prerequisites

**Basic Knowledge Required:**  
- Familiarity with command line/terminal  
- Basic understanding of Python  
- Knowledge of network concepts (flows, packets)  

**Technical Requirements:**  
- Computer with 8GB+ RAM (16GB recommended)  
- Python 3.8 or higher installed  
- 5GB+ free disk space  
- Internet connection (for initial setup)  

---

## 2. Getting Started

### 2.1 Quick Start Checklist  

Before diving in, ensure you have:  

- [ ] Python 3.8+ installed  
- [ ] Dataset downloaded (MIRAGE-2019 or custom)  
- [ ] All dependencies installed  
- [ ] Project files downloaded  
- [ ] 30-60 minutes for first-time setup  

### 2.2 System Overview  

```
┌─────────────────┐
│  Input: JSON    │
│  Traffic Files  │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Step 1: Data    │
│ Aggregation     │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Step 2: Feature │
│ Preprocessing   │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Step 3: Model   │
│ Training (RF)   │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Step 4: Model   │
│ Evaluation      │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Step 5: QoS     │
│ Analysis        │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Output: Model   │
│ & Reports       │
└─────────────────┘
```

### 2.3 What You'll Get  

After running the system, you will have:  

1. **Trained Model** (`model.pkl`) - Ready for deployment  
2. **Performance Metrics** - Accuracy, F1-scores, confusion matrix  
3. **QoS Recommendations** - Priority levels for each application  
4. **Visualizations** - Charts showing traffic distribution and performance  
5. **Processed Dataset** (`Mirage_flows.csv`) - For future analysis  

---

## 3. Installation Guide

### 3.1 Installing Python

#### Windows

1. Download Python from [python.org](https://www.python.org/downloads/)  
2. Run the installer  
3. **IMPORTANT:** Check "Add Python to PATH"  
4. Click "Install Now"  
5. Verify installation:  
   ```cmd
   python --version
   ```
   Should show: `Python 3.8.x` or higher

#### macOS

**Option 1: Using Homebrew (Recommended)**
```bash
# Install Homebrew if not already installed
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install Python
brew install python@3.9

# Verify
python3 --version
```

**Option 2: Download from python.org**  
1. Visit [python.org/downloads/macos](https://www.python.org/downloads/macos/)  
2. Download the macOS installer  
3. Run the .pkg file  
4. Follow installation prompts  

#### Linux (Ubuntu/Debian)

```bash
# Update package list
sudo apt update

# Install Python and pip
sudo apt install python3.9 python3-pip

# Verify installation
python3 --version
pip3 --version
```

### 3.2 Downloading the Project

#### Option 1: Using Git (Recommended)

```bash
# Install Git if needed  
# Windows: Download from git-scm.com  
# macOS: brew install git  
# Linux: sudo apt install git  

# Clone the repository
git clone https://github.com/tomRiddle-the1st/network_traffic_classification.git   

# Navigate to project directory
cd network_traffic_classification
```

#### Option 2: Direct Download

1. Visit the GitHub repository  
2. Click "Code" → "Download ZIP"  
3. Extract the ZIP file to your desired location  
4. Open terminal/command prompt in that folder  

### 3.3 Setting Up Virtual Environment  

A virtual environment keeps your project dependencies isolated.  

#### Windows

```cmd
# Navigate to project folder
cd path\to\network_traffic_classification

# Create virtual environment
python -m venv venv

# Activate virtual environment
venv\Scripts\activate

# You should see (venv) in your prompt
```

#### macOS/Linux

```bash
# Navigate to project folder
cd path/to/network_traffic_classification

# Create virtual environment
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate

# You should see (venv) in your prompt
```

### 3.4 Installing Dependencies

With your virtual environment activated:

```bash
# Install all required packages
pip install -r requirements.txt

# This will install:
# - pandas (data manipulation)  
# - numpy (numerical computing)  
# - scikit-learn (machine learning)  
# - matplotlib (plotting)  
# - seaborn (statistical visualization)  
# - imbalanced-learn (handling class imbalance)  
# - joblib (model persistence)  
# - scipy (scientific computing)  
```

**Installation Progress:**
```
Collecting pandas>=1.3.0
  Downloading pandas-1.5.3.tar.gz (5.2 MB)
Collecting numpy>=1.21.0
  Downloading numpy-1.24.2.tar.gz (10.9 MB)
...
Successfully installed pandas-1.5.3 numpy-1.24.2 scikit-learn-1.2.1 ...
```

### 3.5 Verifying Installation

Run this verification script:

```bash
python -c "
import pandas as pd  
import numpy as np  
import sklearn  
import matplotlib  
import seaborn  
import imblearn  
import joblib  
import scipy  

print(' All dependencies installed successfully!')  
print(f'  - pandas: {pd.__version__}')  
print(f'  - numpy: {np.__version__}')  
print(f'  - scikit-learn: {sklearn.__version__}')  
print(f'  - matplotlib: {matplotlib.__version__}')  
print(f'  - seaborn: {seaborn.__version__}')  
"
```

**Expected Output:**
```
 All dependencies installed successfully!  
  - pandas: 1.5.3  
  - numpy: 1.24.2  
  - scikit-learn: 1.2.1  
  - matplotlib: 3.7.0  
  - seaborn: 0.12.2  
```

### 3.6 Troubleshooting Installation

#### Problem: "pip: command not found"

**Solution:**
```bash
# Try using python -m pip instead
python -m pip install -r requirements.txt

# Or python3 on macOS/Linux
python3 -m pip install -r requirements.txt
```

#### Problem: "Permission denied"

**Solution (Linux/macOS):**
```bash
# Don't use sudo with virtual environments
# Instead, ensure virtual environment is activated
source venv/bin/activate
pip install -r requirements.txt
```

#### Problem: Package installation fails

**Solution:**
```bash
# Update pip first
pip install --upgrade pip

# Then retry
pip install -r requirements.txt

# If still failing, install packages individually
pip install pandas
pip install numpy
pip install scikit-learn
# ... etc
```

---

## 4. Understanding the System

### 4.1 How It Works

The system operates in five main steps:

#### Step 1: Data Aggregation    
- Reads JSON files from the `data/` folder  
- Extracts application labels from filenames  
- Converts flow features into tabular format  
- Saves processed data to `Mirage_flows.csv`  
 
#### Step 2: Preprocessing  
- Removes constant features (zero variance)  
- Handles missing values  
- Standardizes feature scales  
- Analyzes class distribution  

#### Step 3: Model Training  
- Applies Random Oversampling to balance classes  
- Optional: Applies Linear Discriminant Analysis (LDA)  
- Trains Random Forest classifier (300 trees)  
- Splits data: 80% training, 20% testing  

#### Step 4: Model Evaluation  
- Calculates accuracy and F1-scores  
- Generates confusion matrix  
- Identifies top important features  
- Evaluates QoS priority-level performance  
 
#### Step 5: QoS Analysis  
- Maps applications to QoS policies  
- Generates distribution charts  
- Provides deployment recommendations  

### 4.2 Key Concepts

#### Network Flows  
A **flow** is a sequence of packets sharing:   
- Source IP and port  
- Destination IP and port  
- Transport protocol (TCP/UDP)  
- Time window  

**Example Flow Features:**  
```
Flow ID: 192.168.1.100:12345 → 8.8.8.8:443  
Duration: 45 seconds  
Forward packets: 150  
Backward packets: 120  
Avg packet size: 512 bytes  
Inter-arrival time: 0.3 seconds  
```

#### Feature Extraction
The system uses statistical features:  
- **Packet Length:** Mean, std, min, max  
- **Inter-Arrival Time:** Time between packets  
- **Flow Duration:** Total connection time  
- **Packet Count:** Forward and backward  
- **Direction:** Upstream vs downstream traffic  

#### QoS Policies  
Each application gets four QoS parameters:  

1. **Priority:** How urgently traffic should be handled  
   - High: Real-time apps (Waze, Messenger)  
   - Medium: Interactive apps (YouTube, Facebook)  
   - Low: Background apps (Dropbox, Trello)  

2. **Bandwidth:** Required data rate  
   - High: Video streaming (YouTube)  
   - Medium: Music streaming (Spotify)  
   - Low: Text-based apps (Twitter)  

3. **Latency Sensitivity:** Delay tolerance  
   - Very High: Gaming (Slither.io)  
   - High: Navigation (Waze)  
   - Medium: Social media (Facebook)  
   - Low: File storage (Dropbox)  

4. **Jitter Tolerance:** Packet delay variation acceptance
   - Very Low: Gaming  
   - Low: VoIP (Viber)  
   - Medium: Streaming  
   - High: Downloads  

### 4.3 Machine Learning Techniques

#### Random Forest Classifier
An ensemble of decision trees that votes on classifications.

**Advantages:**  
- Robust to overfitting  
- Handles non-linear relationships  
- Provides feature importance  
- Works well with imbalanced data  

**Configuration:**  
```python  
RandomForestClassifier(
    n_estimators=300,      # 300 decision trees
    max_depth=25,          # Maximum tree depth
    class_weight='balanced' # Handle class imbalance
)
```

#### Random Oversampling
Duplicates minority class samples to balance dataset.

**Before Oversampling:**
```
waze:      1,234 flows
youtube:  15,678 flows  ← Majority class
spotify:   3,456 flows
```

**After Oversampling:**
```
waze:     15,678 flows  ← Balanced
youtube:  15,678 flows
spotify:  15,678 flows
```

#### Linear Discriminant Analysis (Optional)
Reduces feature dimensions while preserving class separability.

**Example:**
- Input: 102 features
- Output: 19 LDA components (for 20 classes)
- Benefit: Faster training, reduced overfitting

### 4.4 Performance Metrics

#### Accuracy
Percentage of correctly classified flows:
```
Accuracy = (Correct Predictions) / (Total Predictions)
         = 21,897 / 24,391
         = 89.76%
```

#### F1-Score
Harmonic mean of precision and recall:
```
Precision = True Positives / (True Positives + False Positives)
Recall = True Positives / (True Positives + False Negatives)
F1-Score = 2 × (Precision × Recall) / (Precision + Recall)
```

**Interpretation:**
- F1 = 1.0: Perfect classification
- F1 > 0.9: Excellent
- F1 = 0.7-0.9: Good
- F1 < 0.7: Needs improvement

#### Confusion Matrix
Shows actual vs predicted classifications:
Script generates a Confusion matrix
```
              Predicted
           YouTube  Waze  Spotify
Actual
YouTube      1450    30      20
Waze           25  1380      15
Spotify        35    20    1425
```

**Reading the Matrix:**
- Diagonal: Correct classifications
- Off-diagonal: Misclassifications
- Row sums: Actual class counts
- Column sums: Predicted class counts

---

## 5. Preparing Your Data

### 5.1 Using the MIRAGE-2019 Dataset

#### Downloading MIRAGE-2019

1. **Visit Kaggle:**  
   - Go to: https://www.kaggle.com/datasets/programmerrdai/mirage-2019  
   - Create a Kaggle account if needed  

2. **Download the Dataset:**
   - Click "Download" (may require verification)  
   - Extract the ZIP file  
   - You'll see folders for two devices Google Nexus and Xiaomi Mi5  

3. **Organize Files:**
   ```bash  
   # Create data directory in your project
   mkdir data
   
   # Copy JSON files from MIRAGE-2019
   cp /path/to/MIRAGE-2019/com.waze/*.json data/
   cp /path/to/MIRAGE-2019/com.spotify.music/*.json data/
   # ... repeat for other apps
   ```

#### Supported Applications

The system recognizes these MIRAGE-2019 applications:

| Application | Package Name | QoS Priority |
|------------|--------------|--------------|
| Waze | com.waze | High |
| Spotify | com.spotify.music | High |
| Viber | com.viber.voip | High |
| Slither.io | air.com.hypah.io.slither | High |
| Messenger | com.facebook.orca | High |
| YouTube | com.google.android.youtube | Medium |
| Facebook | com.facebook.katana | Medium |
| Twitter | com.twitter.android | Medium |
| Pinterest | com.pinterest | Medium |
| Wish | com.contextlogic.wish | Medium |
| Groupon | com.groupon | Medium |
| Subito | it.subito | Medium |
| TripAdvisor | com.tripadvisor.tripadvisor | Medium |
| Foursquare | com.joelapenna.foursquared | Medium |
| AccuWeather | com.accuweather.android | Medium |
| iLiga | motain.iliga | Medium |
| Dropbox | com.dropbox.android | Low |
| Trello | com.trello | Low |
| Duolingo | com.duolingo | Low |
| Comics | com.iconology.comics | Low |

### 5.2 Dataset Structure

#### JSON File Format

Each JSON file contains multiple network flows:

```json
{
  "flow_id_1": {
    "flow_features": {
      "packet_length": {
        "forward": {
          "mean": 512.3,
          "std": 120.5,
          "min": 60,
          "max": 1500
        },
        "backward": {
          "mean": 380.2,
          "std": 95.3,
          "min": 40,
          "max": 1200
        }
      },
      "inter_arrival_time": {
        "forward": {
          "mean": 0.025,
          "std": 0.012
        },
        "backward": {
          "mean": 0.030,
          "std": 0.015
        }
      }
    }
  },
  "flow_id_2": {
    ...
  }
}
```

#### Required Feature Structure

The system expects these feature categories:
- `packet_length`: Statistics on packet sizes  
- `inter_arrival_time`: Time between packets  
- `flow_duration`: Total flow duration  
- `packet_count`: Number of packets  

Each category should have:
- `forward`: Upstream traffic statistics  
- `backward`: Downstream traffic statistics  

Each direction should include:
- `mean`: Average value  
- `std`: Standard deviation  
- `min`: Minimum value  
- `max`: Maximum value  
 
### 5.3 Using Custom Datasets

#### Format Requirements

To use your own traffic data:

1. **Convert to JSON format:**
   ```python
   import json
   
   flows = {
       "flow_1": {
           "flow_features": {
               "packet_length": {
                   "forward": {"mean": 512, "std": 120},
                   "backward": {"mean": 380, "std": 95}
               }
           }
       }
   }
   
   with open('myapp_traffic.json', 'w') as f:
       json.dump(flows, f, indent=2)
   ```

2. **Name files with application identifier:**  
   - Good: `com.myapp_2025_01_15.json`  
   - Good: `mycompany.myapp_flows.json`  
   - Bad: `traffic_data.json` (no app identifier)  

3. **Place files in data/ directory:**
   ```
   data/
   ├── com.myapp1_flows.json
   ├── com.myapp2_flows.json
   └── com.myapp3_flows.json
   ```

#### Updating Label Extraction

If your filenames don't match the expected pattern, modify the `extract_label()` function:

```python
def extract_label(filename):
    # Example: Extract from custom format
    # Filename: "myapp_traffic_2025.json" → Label: "myapp"
    
    name = os.path.splitext(filename)[0]
    
    if "myapp" in name.lower():
        return "myapp"
    elif "otherapp" in name.lower():
        return "otherapp"
    
    # Fall back to existing logic
    # ... (keep existing code)
```

#### Adding Custom QoS Policies

Define QoS requirements for your applications:

```python
qos_policies = {
    'myapp': {
        'priority': 'high',              # high/medium/low
        'bandwidth': 'medium',           # low/medium/high/variable
        'latency_sensitivity': 'high',   # low/medium/high/very_high
        'jitter_tolerance': 'low'        # very_low/low/medium/high
    },
    'otherapp': {
        'priority': 'medium',
        'bandwidth': 'low',
        'latency_sensitivity': 'medium',
        'jitter_tolerance': 'high'
    },
    # ... existing policies
}
```

### 5.4 Data Quality Checks

#### Verifying Your Dataset

Before running the system, check:

**1. File Count:**
```bash
# Count JSON files
ls data/*.json | wc -l

# Should have at least 3-5 files for meaningful results
```

**2. File Sizes:**
```bash
# Check file sizes
ls -lh data/

# Each file should be > 10KB
# Files < 1KB are likely empty or corrupted
```

**3. JSON Validity:**
```python
import json
import os

data_folder = "data"
for file in os.listdir(data_folder):
    if file.endswith('.json'):
        try:
            with open(os.path.join(data_folder, file)) as f:
                json.load(f)
            print(f"✓ {file}")
        except json.JSONDecodeError:
            print(f"✗ {file} - INVALID JSON")
```

**4. Flow Count:**
```python
import json
import os

total_flows = 0
for file in os.listdir("data"):
    if file.endswith('.json'):
        with open(os.path.join("data", file)) as f:
            data = json.load(f)
            flows = len(data)
            print(f"{file}: {flows} flows")
            total_flows += flows

print(f"\nTotal flows: {total_flows}")
# Aim for 1000+ flows per application
```

#### Common Data Issues

**Issue 1: Inconsistent Feature Names**
```python  
# Problem: Features named differently across files  
# file1.json: "packet_length"  
# file2.json: "pkt_len"  

# Solution: Standardize feature names before processing  
# Or modify process_file() to handle variations  
```

**Issue 2: Missing Values**
```python  
# Problem: Some flows missing certain features  

# Solution: The system handles this automatically  
# Missing values are filled with 0 in preprocessing   
```

**Issue 3: Extreme Values**  
```python  
# Problem: Outliers (e.g., packet_length = 999999)  

# Solution: Consider adding outlier detection  
# Or clip values to reasonable ranges:  
X = X.clip(lower=X.quantile(0.01), upper=X.quantile(0.99), axis=1)
```

---

## 6. Running the Classification System

### 6.1 First Run

#### Step-by-Step Execution

**1. Activate Virtual Environment:**
```bash
# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

**2. Verify Data:**
```bash
# Check data directory exists
ls data/

# Should see JSON files
com.waze_flows.json
com.spotify.music_flows.json
...
```

**3. Run the System:**
```bash
python network_traffic_classification.py
```

**4. Monitor Progress:**
The system will print status updates:
```
NETWORK TRAFFIC CLASSIFICATION

Step 1: Aggregating flow data...  
Processing waze with 1234 flows  
Processing youtube with 5678 flows  
Processing spotify with 3456 flows  
... (continues for all applications)  
Saved aggregate dataset to output/Mirage_flows.csv  

Step 2: Preprocessing...  
Dataset shape: (121955, 102)  
Number of apps: 20  
[Bar chart displayed showing traffic distribution]  

Step 3: Train model...  
Applied Random Oversampling: (121955, 102) ...flows sample to (237300, 102)  
Train set: (189840, 102)  
Test set: (47460, 102)  
Training model...  
Model training completed!  
Total training time: 2.00 minutes and 15.43 seconds  

Step 4: Evaluating model performance...  
Accuracy: 0.8976  
Macro F1-Score: 0.8971  
Weighted F1-Score: 0.8971  
[Confusion matrix displayed]  
[Classification report printed]  
[QoS recommendations listed]  

Step 5: QoS analysis (with charts)...  
Priority Distribution:  
high  :  45234 flows ( 18.7%)  
medium: 178456 flows ( 73.8%)  
low   :  13610 flows (  5.6%)  
[Pie charts displayed]  

Saving Model and Metadata  
Model and metadata saved to output/model.pkl  
Feature scaler saved to output/feature_scaler.pkl  

Execution completed successfully  
Total execution time: 5 minutes and 32.18 seconds  
```

### 6.2 Understanding Console Output

#### Step 1 Output  
```
Processing waze with 1234 flows  
```
- Shows each application being processed  
- Flow count indicates data volume  
- Warning if <100 flows (may affect accuracy)  

#### Step 2 Output  
```
Dataset shape: (121955, 102)  
Number of apps: 20  
```
- First number: Total flows  
- Second number: Total features   
- Apps count: Number of applications  

A bar chart will appear showing:  
- X-axis: Applications  
- Y-axis: Number of flows  
- Colors: QoS priority (blue=high, orange=medium, beige=low)  

#### Step 3 Output  
```
Applied Random Oversampling: (121955, 102) ...flows sample to (237300, 102)  
Train set: (189840, 102)  
Test set: (47460, 102)   
```
- Shows data before/after oversampling  
- 80% used for training  
- 20% reserved for testing  
- Training time: Typically 2-5 minutes  

#### Step 4 Output
```
Accuracy: 0.8976  
Macro F1-Score: 0.8971  
Weighted F1-Score: 0.8971  
```
- **Accuracy:** Overall correctness (89.76% is excellent)  
- **Macro F1:** Average performance across all apps  
- **Weighted F1:** Performance weighted by class size  

A confusion matrix heatmap appears showing:  
- Correct classifications (diagonal)  
- Misclassifications (off-diagonal)  
- Color intensity indicates count  

#### Step 5 Output
```
Priority Distribution:
high  :  45234 flows ( 18.7%)  
medium: 178456 flows ( 73.8%)  
low   :  13610 flows (  5.6%)  
```
Shows how traffic is distributed across QoS priorities.  

Three pie charts appear:  
1. **Priority Distribution:** High/Medium/Low  
2. **Latency Sensitivity:** Very High/High/Medium/Low  
3. **Bandwidth Requirements:** High/Medium/Low/Variable  

### 6.3 Interacting with Visualizations  

#### Viewing Charts  

When charts appear:  
- **Close Window:** Click X or press Q  
- **Save Chart:** Right-click → Save to desired folder
- **OR Charts get saved to charts folder  
- **Zoom:** Use toolbar buttons  
- **Pan:** Hold and drag  

Charts are automatically saved to `output/charts/`:
- `traffic_distribution.png`  
- `priority_distribution.png`  
- `latency_sensitivity.png`  
- `bandwidth_requirements.png`  
- `confusion_matrix.png`  

#### Chart Interpretation  

**Traffic Distribution Bar Chart:**  
```
High Priority (Blue): Real-time apps (Waze, Messenger)  
Medium Priority (Orange): Interactive apps (YouTube, Facebook)  
Low Priority (Beige): Background apps (Dropbox, Trello)  
```

**Priority Pie Chart:**
Shows percentage of traffic in each priority category.  
- Large "High" slice: Many real-time apps  
- Large "Medium" slice: Typical mobile usage  
- Small "Low" slice: Less background traffic  

**Confusion Matrix:**
- Dark red: Many flows (correct classifications)  
- Light colors: Few flows  
- Off-diagonal dark spots: Confusion between apps  
  - Example: YouTube ↔ Spotify (both streaming)  

### 6.4 Stopping the Process

If you need to stop execution:

**Windows:**
```
Press Ctrl + C

# System will display:
KeyboardInterrupt
^C
# May need to close matplotlib windows manually
```

**macOS/Linux:**
```
Press Ctrl + C

# Or from another terminal:
ps aux | grep python
kill <process_id>
```

**What Happens:**  
- Partial results may be lost  
- Generated files (if any) remain  
- Next run starts fresh  
- No data corruption  

### 6.5 Common First-Run Issues  

#### Issue 1: No Data Found  
```
ValueError: No JSON files found in data folder  
```

**Solution:** 
```bash
# Check data directory
ls data/

# If empty, add JSON files
cp /path/to/MIRAGE/files/*.json data/
```

#### Issue 2: Memory Error
```
MemoryError: Unable to allocate array
```

**Solution:**
```python
# In network_traffic_classification.py, add after line 260:
if len(data) > 50000:
    data = data.sample(n=50000, random_state=42)
    print(f"Sampled dataset to 50000 flows")
```

#### Issue 3: Matplotlib Not Showing
```
# Charts generated but not displayed
```

**Solution:**
```python
# Add at top of script, after imports:
import matplotlib
matplotlib.use('TkAgg')  # Or 'Qt5Agg'
```

#### Issue 4: Slow Performance
```
# Training takes >10 minutes
```

**Solution:**
```python
# Reduce model complexity:
rf_model = RandomForestClassifier(
    n_estimators=100,      # Was 300
    max_depth=15,          # Was 25
    n_jobs=4               # Was -1
)
```

---

## 7. Configuration Options

### 7.1 Basic Configuration

Edit these variables at the top of `network_traffic_classification.py`:

```python
#============================================
# CONFIGURATION SETTINGS
#============================================

# Directory Settings
data_folder = "data"                      # Input JSON files
output_folder = "output"                  # Output files
charts_folder = "charts"                  # Saved charts

# File Names
processed_data = "Mirage_flows.csv"       # Processed dataset
Model = "model.pkl"                       # Trained model
scaler_file = "feature_scaler.pkl"        # Feature scaler
lda_file = "lda_transformer.pkl"          # LDA transformer

# Machine Learning Toggles
use_SMOTE = False                         # SMOTE oversampling
use_random_oversampling = True            # Random oversampling (recommended)
use_lda = False                           # Dimensionality reduction

# Display Settings
top_features = 10                         # Number of features to show
```

### 7.2 Oversampling Strategies

#### Random Oversampling (Default)

**When to Use:**  
- General purpose (works for most cases)  
- Fast and simple  
- Good with small datasets  

**Configuration:**  
```python
use_SMOTE = False
use_random_oversampling = True
```

**How It Works:**
Randomly duplicates minority class samples until balanced.  

**Pros:**  
- Simple and fast  
- No synthetic data generation  
- Preserves original data distribution  

**Cons:**  
- May cause overfitting  
- No new information added  

#### SMOTE (Alternative)

**When to Use:**
- Need synthetic samples  
- Have sufficient data (>1000 samples/class)  
- Want to reduce overfitting  

**Configuration:**
```python
use_SMOTE = True
use_random_oversampling = False
```

**How It Works:**
Creates synthetic samples by interpolating between existing minority class samples.

**Pros:**
- Generates new, realistic samples  
- Better generalization  
- Reduces overfitting risk  

**Cons:**  
- Slower than random oversampling  
- May create unrealistic samples in high dimensions  
- Requires more memory  

#### No Oversampling

**When to Use:**
- Dataset is already balanced  
- Testing baseline performance  
- Limited computational resources  

**Configuration:**
```python
use_SMOTE = False
use_random_oversampling = False
```

**Impact:**
- Faster training  
- May have lower accuracy for minority classes  
- Good for understanding raw dataset performance  

### 7.3 Dimensionality Reduction (LDA)  

#### Enabling LDA  

**When to Use:**  
- Dataset has many features (>100)  
- Training is slow  
- Want to reduce overfitting  
- Need faster predictions  

**Configuration:**
```python
use_lda = True
```

**How It Works:**  
Linear Discriminant Analysis projects features onto a lower-dimensional space while maximizing class separability.  

**Example:**
- Input: 102 features
- Output: 19 LDA components (for 20 classes)
- Reduction: ~80% fewer features

**Benefits:**  
- Faster training (50-70% speed increase)  
- Reduced memory usage  
- May improve generalization  
- Removes redundant features  

**Drawbacks:**  
- May lose some information  
- Cannot extract original feature importance  
- Maximum components = (number of classes - 1)  

#### Disabling LDA (Default)  

**Configuration:**  
```python  
use_lda = False
```

**Benefits:**  
- Preserves all original features  
- Can analyze feature importance  
- No information loss  
- Better interpretability  

**Drawbacks:**
- Slower training  
- More memory usage  
- May overfit on redundant features  

### 7.4 Random Forest Parameters

#### Basic Parameters

Located in the `train_model()` function:

```python
rf_model = RandomForestClassifier(
    n_estimators=300,              # Number of trees
    max_depth=25,                  # Maximum tree depth
    min_samples_split=5,           # Min samples to split node
    min_samples_leaf=2,            # Min samples at leaf
    class_weight="balanced",       # Handle imbalance
    random_state=42,               # Reproducibility
    n_jobs=-1                      # CPU cores to use
)
```

#### Parameter Tuning Guide

**n_estimators (Number of Trees):**
```python
# Accuracy vs Speed tradeoff
n_estimators=100      # Fast, may underfit
n_estimators=300      # Balanced (default)
n_estimators=500      # Slower, marginal gains
```

**Effect on Performance:**
- More trees → Higher accuracy (plateaus after ~300)
- More trees → Longer training time
- More trees → Larger model file

**max_depth (Tree Depth):**
```python
# Overfitting vs Underfitting
max_depth=10          # Simple trees, may underfit
max_depth=25          # Balanced (default)
max_depth=None        # Unlimited, may overfit
```

**Guidelines:**
- Shallow trees (10-15): Better generalization, faster  
- Deep trees (25-30): Better training accuracy  
- Unlimited depth: Risk of overfitting  

**min_samples_split:**
```python
# Minimum samples required to split a node
min_samples_split=2   # More splits, complex trees
min_samples_split=5   # Balanced (defaul t)
min_samples_split=10  # Fewer splits, simpler trees
```

**min_samples_leaf:**
```python
# Minimum samples at each leaf node
min_samples_leaf=1    # More detailed trees
min_samples_leaf=2    # Balanced (default)
min_samples_leaf=5    # Simpler trees
```

**n_jobs (Parallel Processing):**
```python
n_jobs=1              # Single core (slow)
n_jobs=4              # Use 4 cores
n_jobs=-1             # Use all available cores (default)
```

#### Recommended Configurations

**For High Accuracy:**
```python
rf_model = RandomForestClassifier(
    n_estimators=500,
    max_depth=30,
    min_samples_split=2,
    min_samples_leaf=1,
    class_weight="balanced",
    random_state=42,
    n_jobs=-1
)
```
- Expected accuracy: +2-3%
- Training time: 2-3x longer
- Model size: 2x larger

**For Fast Training:**
```python
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight="balanced",
    random_state=42,
    n_jobs=-1
)
```
- Expected accuracy: -3-5%
- Training time: 3x faster
- Model size: 3x smaller

**For Memory-Constrained Systems:**
```python
rf_model = RandomForestClassifier(
    n_estimators=50,
    max_depth=10,
    min_samples_split=20,
    min_samples_leaf=10,
    class_weight="balanced",
    random_state=42,
    n_jobs=2  # Limit CPU usage
)
```

### 7.5 Train-Test Split

#### Adjusting Split Ratio

Located in `train_model()` function:

```python
X_train, X_test, y_train, y_test = train_test_split(
    X_final, y_resampled,
    test_size=0.2,              # 20% for testing
    stratify=y_resampled,       # Maintain class proportions
    random_state=42             # Reproducible results
)
```

**Options:**
```python
test_size=0.1    # 90% train, 10% test - More training data  
test_size=0.2    # 80% train, 20% test - Balanced (default)  
test_size=0.3    # 70% train, 30% test - More evaluation data  
```

**Guidelines:**
- **Large datasets (>50K flows):** Use 0.2 or 0.3  
- **Small datasets (<10K flows):** Use 0.1 or 0.15  
- **Very small datasets (<5K flows):** Consider cross-validation  

#### Reproducibility

```python
random_state=42    # Fixed seed - Same results every run  
random_state=None  # Random seed - Different results each run  
```

**When to change:**    
- Testing model stability: Use `None` and run multiple times  
- Production deployment: Use fixed seed (e.g., 42)  
- Comparing configurations: Use same seed  

### 7.6 QoS Policy Customization  

#### Adding New Applications  

```python
qos_policies = {
    # Add your application here
    'mynewapp': {
        'priority': 'high',              # high/medium/low
        'bandwidth': 'medium',           # low/medium/high/variable
        'latency_sensitivity': 'high',   # low/medium/high/very_high
        'jitter_tolerance': 'low'        # very_low/low/medium/high
    },
    
    # Existing applications
    'waze': {...},
    'spotify': {...},
    # ...
}
```

#### QoS Policy Guidelines

**Priority Levels:**  
- **High:** Real-time applications (gaming, navigation, VoIP)  
  - Examples: Waze, Slither.io, Viber  
- **Medium:** Interactive applications (streaming, social media)  
  - Examples: YouTube, Facebook, Spotify  
- **Low:** Background applications (cloud storage, productivity)  
  - Examples: Dropbox, Trello, Duolingo  

**Bandwidth Requirements:**  
- **High:** Video streaming, video calls  
  - Examples: YouTube (5-20 Mbps)  
- **Medium:** Music streaming, image-heavy apps  
  - Examples: Spotify (160-320 kbps), Instagram  
- **Low:** Text-based apps, lightweight apps  
  - Examples: Twitter, Weather apps  
- **Variable:** File sync, downloads  
  - Examples: Dropbox, cloud backup  

**Latency Sensitivity:**
- **Very High:** Online gaming, real-time control  
  - Target: <20ms  
  - Examples: Slither.io, multiplayer games  
- **High:** Navigation, VoIP, video calls  
  - Target: 20-50ms  
  - Examples: Waze, Messenger calls  
- **Medium:** Social media, web browsing, streaming  
  - Target: 50-150ms  
  - Examples: Facebook, YouTube  
- **Low:** File transfers, email, cloud storage  
  - Target: >150ms acceptable  
  - Examples: Dropbox, email clients  

**Jitter Tolerance:**  
- **Very Low:** Real-time gaming  
  - Max jitter: <10ms  
- **Low:** VoIP, video calls  
  - Max jitter: 10-30ms  
- **Medium:** Video streaming  
  - Max jitter: 30-50ms (buffering helps)  
- **High:** Downloads, messaging  
  - Max jitter: >50ms acceptable  

#### Example QoS Policies by Category  

**Navigation Apps:** 
```python
'waze': {
    'priority': 'high',
    'bandwidth': 'medium',
    'latency_sensitivity': 'high',
    'jitter_tolerance': 'low'
}
```

**Gaming Apps:**
```python
'slither': {
    'priority': 'high',
    'bandwidth': 'medium',
    'latency_sensitivity': 'very_high',
    'jitter_tolerance': 'very_low'
}
```

**Video Streaming:**
```python
'youtube': {
    'priority': 'medium',
    'bandwidth': 'high',
    'latency_sensitivity': 'medium',
    'jitter_tolerance': 'medium'
}
```

**Music Streaming:**
```python
'spotify': {
    'priority': 'high',
    'bandwidth': 'medium',
    'latency_sensitivity': 'medium',
    'jitter_tolerance': 'medium'
}
```

**Social Media:**
```python
'facebook': {
    'priority': 'medium',
    'bandwidth': 'medium',
    'latency_sensitivity': 'medium',
    'jitter_tolerance': 'high'
}
```

**Cloud Storage:**
```python
'dropbox': {
    'priority': 'low',
    'bandwidth': 'variable',
    'latency_sensitivity': 'low',
    'jitter_tolerance': 'high'
}
```

### 7.7 Display Settings  

#### Top Features Count   

```python
top_features = 10    # Show top 10 most important features
```

**Options:**
- `top_features = 5`: Quick overview  
- `top_features = 10`: Balanced (default)  
- `top_features = 20`: Detailed analysis  
- `top_features = 50`: Comprehensive view  

**Note:** Only applicable when `use_lda = False`

#### Chart Settings

Modify in the visualization functions:

```python
# Figure size
plt.figure(figsize=(16, 8))      # Width x Height in inches

# Color schemes
colors = ['#0881a3', '#ffd6a4', '#fde9df']  # High, Medium, Low

# Font sizes
plt.title("Chart Title", fontsize=14, fontweight='bold')
plt.xlabel("X Label", fontsize=12)

# DPI (resolution)
plt.savefig(path, dpi=200)       # Higher = better quality, larger file
```

### 7.8 Configuration Examples

#### Example 1: Quick Testing
```python
# Fast configuration for testing
use_SMOTE = False
use_random_oversampling = True
use_lda = True                   # Speed up training
top_features = 5

rf_model = RandomForestClassifier(
    n_estimators=100,            # Fewer trees
    max_depth=15,                # Shallower trees
    n_jobs=-1
)
```

#### Example 2: Maximum Accuracy
```python
# Best accuracy configuration
use_SMOTE = True                 # Better synthetic samples
use_random_oversampling = False
use_lda = False                  # Keep all features
top_features = 20

rf_model = RandomForestClassifier(
    n_estimators=500,            # More trees
    max_depth=30,                # Deeper trees
    min_samples_split=2,
    min_samples_leaf=1,
    n_jobs=-1
)
```

#### Example 3: Production Deployment
```python
# Balanced for deployment
use_SMOTE = False
use_random_oversampling = True   # Faster than SMOTE
use_lda = True                   # Smaller model
top_features = 10

rf_model = RandomForestClassifier(
    n_estimators=300,
    max_depth=25,
    class_weight="balanced",
    random_state=42,             # Reproducible
    n_jobs=-1
)
```

---

## 8. Understanding the Results

### 8.1 Performance Metrics Explained

#### Overall Accuracy

```
Accuracy: 0.8976 (89.76%)
```

**What it means:**  
- 89.76% of flows were correctly classified  
- Out of 24,391 test flows, 21,897 were correct  
- This is excellent performance for 20-class classification  

**Interpretation:**  
- **>90%:** Excellent - Ready for production  
- **85-90%:** Good - Minor tuning may help  
- **80-85%:** Acceptable - Consider improvements  
- **<80%:** Needs improvement - Check data quality  

#### F1-Scores

```
Macro F1-Score: 0.8971  
Weighted F1-Score: 0.8971  
```

**Macro F1-Score:**  
- Average F1 across all classes (unweighted)  
- Treats all applications equally  
- Good for understanding overall model quality  

**Weighted F1-Score:**  
- Average F1 weighted by class size  
- Emphasizes performance on larger classes  
- Better reflects real-world usage  

**When scores differ significantly:**
```
Macro F1: 0.75    }   
Weighted F1: 0.88 } Large difference  

# Indicates:
# - Good performance on common apps (YouTube, Facebook)  
# - Poor performance on rare apps (Comics, Trello)  
# - Model biased toward majority classes  
```

#### Per-Class Metrics

The classification report shows detailed metrics for each application:

```
             precision    recall  f1-score   support

accuweather      0.8728  0.7977    0.8336   2373.0000
comics           0.9044  0.8934    0.8989   2373.0000
dropbox          0.8539  0.8622    0.8580   2373.0000
duolingo         0.8010  0.7889    0.7949   2373.0000
facebook         0.8186  0.8403    0.8293   2373.0000
...
```

**Columns explained:**  
- **precision:** Of predicted "YouTube" flows, what % were actually YouTube?  
  - `precision = True Positives / (True Positives + False Positives)`  
  - High precision = Few false alarms  

- **recall:** Of actual YouTube flows, what % did we catch?  
  - `recall = True Positives / (True Positives + False Negatives)`  
  - High recall = Few missed detections  

- **f1-score:** Harmonic mean of precision and recall  
  - `f1 = 2 × (precision × recall) / (precision + recall)`  
  - Balanced measure of performance  

- **support:** Number of actual flows in test set

**Example interpretation:**
```
youtube: precision=0.92, recall=0.94, f1=0.93

Meaning:
- 92% of flows we labeled "YouTube" were correct  
- We detected 94% of actual YouTube flows  
- Overall YouTube classification: Excellent (F1=0.93)  
```

### 8.2 QoS Priority Analysis

```
Performance by QoS Priority Level:  
High Priority Apps: F1=0.9039 (n=5 apps)  
Medium Priority Apps: F1=0.8444 (n=11 apps)
Low Priority Apps: F1=0.8647 (n=4 apps)
```

**What it means:**
- **High priority apps** (Waze, Messenger, Viber, Slither, Spotify) are classified most accurately
- This is ideal because these apps need the most reliable QoS
- Medium and low priority apps also have good performance

**Why high priority performs best:**
1. Often have distinct traffic patterns
2. Real-time nature creates unique signatures
3. Tend to be more consistently used
4. System correctly prioritizes what matters most

### 8.3 Confusion Matrix Analysis

#### Reading the Matrix

```
Confusion Matrix:
              Predicted
           YouTube  Facebook  Spotify  Waze
Actual
YouTube       1410        45       30    15
Facebook        52      1044       80    24
Spotify         28        65      990    17
Waze            15        30       20   915
```

**Diagonal values (bold):** Correct classifications  
- YouTube: 1410/1500 = 94% correct  

**Off-diagonal values:** Misclassifications  
- YouTube→Facebook: 45 flows misclassified  
- Facebook→Spotify: 80 flows confused  

#### Common Confusion Patterns  

**Streaming Apps Confusion:**  
```
YouTube ↔ Spotify: Similar streaming patterns  
Solution: Both are medium priority, acceptable confusion  
```

**Social Media Confusion:**
```
Facebook ↔ Twitter ↔ Pinterest: Similar content types  
Solution: Same QoS requirements, minimal impact  
```

**Messaging Confusion:**
```
Messenger ↔ Viber: Both VoIP/messaging apps  
Solution: Both high priority, QoS not affected  
```

**Critical Confusions (Rare but important):**  
```
Dropbox (low priority) ↔ Waze (high priority)  
Impact: HIGH - Would give wrong QoS  
Frequency: Should be <1% with good model  
```

### 8.4 QoS Distribution Analysis  

#### Priority Distribution  

```
Priority Distribution:
high  :  28920 flows ( 23.7%)
medium:  71205 flows ( 58.4%)
low   :  21830 flows ( 17.9%) 
```

**Interpretation:**
- **23.7% high priority:** Real-time, latency-sensitive apps
  - Requires: Priority queuing, low latency
  - Examples: Waze, Messenger, gaming

- **58.4% medium priority:** Interactive apps (majority)
  - Requires: Balanced resource allocation
  - Examples: YouTube, Facebook, Spotify

- **17.9% low priority:** Background tasks
  - Requires: Bandwidth throttling acceptable
  - Examples: Dropbox, email sync

**Network Planning Insights:**
- Reserve 20-25% bandwidth for high priority
- Allocate 70% bandwidth for medium priority
- Use remaining bandwidth for low priority
- Implement priority queuing for high traffic

#### Latency Sensitivity Distribution

```

Latency Sensitivity Distribution:
very_high :   3189 flows (  2.6%)
high      :  19116 flows ( 15.7%)
medium    :  73567 flows ( 60.3%)
low       :  26083 flows ( 21.4%)	
```

**Network Recommendations:**
- **Very High (2.6%):** Target <20ms latency  
  - Gaming, real-time control  
  - Use: Express forwarding, dedicated queues  

- **High (15.7%):** Target <50ms latency  
  - Navigation, VoIP
  - Use: Priority queuing, jitter buffering

- **Medium (60.3%):** Target <150ms latency
  - Streaming, social media
  - Use: Standard best-effort with QoS

- **Low (21.4%):** >150ms acceptable
  - File transfers, background sync
  - Use: Throttling acceptable

#### Bandwidth Distribution

```
Bandwidth Distribution:
high      :   6493 flows (  5.3%)
medium    :  77930 flows ( 63.9%)
low       :  32327 flows ( 26.5%)
variable  :   5205 flows (  4.3%)
```

**Capacity Planning:**
- **High bandwidth (5.3%):** Video streaming  
  - Reserve: 60-70% of total capacity  
  - Peak rates: 5-20 Mbps per flow  

- **Medium bandwidth (63.9%):** Music, images  
  - Reserve: 20-30% of total capacity  
  - Peak rates: 0.5-5 Mbps per flow  

- **Low bandwidth (26.5%):** Text, lightweight  
  - Reserve: 5-10% of total capacity  
  - Peak rates: <500 kbps per flow  

- **Variable (4.3%):** Burst traffic  
  - Reserve: Flexible allocation  
  - Use: Traffic shaping  

### 8.5 Feature Importance Analysis

When `use_lda = False`, you'll see:

```
Top 10 Most Important Features:  
packet_length_forward_mean  
inter_arrival_time_backward_std  
flow_duration_forward_max  
packet_length_backward_std  
packet_count_forward_mean  
flow_duration_backward_mean  
inter_arrival_time_forward_mean  
packet_length_forward_max  
packet_count_backward_std  
flow_duration_forward_std  
```

**Understanding Feature Names:**  
- `packet_length_forward_mean`: Average size of uploaded packets  
- `inter_arrival_time_backward_std`: Variability in download timing  
- `flow_duration_forward_max`: Maximum connection duration  

**What this tells you:**  
1. **Packet length statistics:** Most discriminative features  
   - Different apps send different-sized packets  
   - Example: YouTube (large) vs Twitter (small)  

2. **Timing patterns:** Important for classification  
   - Gaming: Very regular timing  
   - Browsing: Bursty, irregular timing  

3. **Flow duration:** Helps distinguish app types  
   - Streaming: Long durations  
   - Messaging: Short bursts  

### 8.6 QoS Recommendations Output  

For each application, you'll see:

```
youtube:  
  Classification Confidence: 0.930  
  Recommended Priority: medium  
  Bandwidth Allocation: high  
  Latency Sensitivity: medium  
  Jitter Tolerance: medium  
```

**Using These Recommendations:**  

1. **Network Configuration:**  
   ```
   # Router/Firewall rules
   IF application == "youtube" THEN  
       SET priority_queue = "medium"  
       SET bandwidth_min = "5 Mbps"  
       SET bandwidth_max = "20 Mbps"  
       SET latency_target = "100 ms"  
       SET jitter_buffer = "50 ms"  
   ```

2. **SDN Controller:**
   ```python  
   qos_policy = {  
       'app': 'youtube',  
       'priority': 2,  # 1=high, 2=medium, 3=low  
       'min_bw': 5000000,  # 5 Mbps in bps  
       'max_bw': 20000000,  
       'dscp': 'AF31'  # DiffServ code point   
   }
   controller.apply_policy(flow_id, qos_policy)  
   ```

3. **Traffic Shaping:**  
   ```bash  
   # Linux TC (Traffic Control)  
   tc qdisc add dev eth0 root handle 1: htb default 30  
   tc class add dev eth0 parent 1: classid 1:1 htb rate 100mbit  
   tc class add dev eth0 parent 1:1 classid 1:10 htb rate 20mbit prio 1  # High  
   tc class add dev eth0 parent 1:1 classid 1:20 htb rate 60mbit prio 2  # Medium  
   tc class add dev eth0 parent 1:1 classid 1:30 htb rate 20mbit prio 3  # Low  
   ```

### 8.7 Interpreting Training Time   

```
Total training time: 2.00 minutes and 15.43 seconds  
```

**Factors affecting training time:**  
1. **Dataset size:** More flows = longer training  
2. **Feature count:** More features = longer training  
3. **Oversampling:** SMOTE slower than Random Oversampling  
4. **LDA:** Can reduce training time if many features  
5. **Random Forest settings:** More trees = longer training  
6. **CPU cores:** More cores = faster with n_jobs=-1  

**Typical training times:**  
- Small dataset (<10K flows): 30-60 seconds  
- Medium dataset (10K-50K flows): 1-3 minutes  
- Large dataset (50K-100K flows): 3-10 minutes  
- Very large (>100K flows): 10-30 minutes  

**When to be concerned:**  
- Training >30 minutes with <100K flows  
- Possible causes: Insufficient RAM, CPU bottleneck, too many features  
- Solutions: Enable LDA, reduce n_estimators, sample dataset  

---

## 9. Using the Trained Model  

### 9.1 Model Files Overview  

After training, you'll have these files in `output/`:  

```
output/  
├── model.pkl (150-200 MB)  
│   Contains:  
│   - Trained Random Forest classifier  
│   - Feature scaler (StandardScaler)  
│   - Feature names list  
│   - Application class labels  
│   - QoS policy mappings  
│   - Training configuration  
│
├── feature_scaler.pkl (<1 MB)  
│   - StandardScaler parameters  
│   - Mean and std for each feature  
│
├── lda_transformer.pkl (<10 MB) [if use_lda=True]  
│   - LDA transformation matrix  
│   - Explained variance ratios  
│
└── Mirage_flows.csv (variable size)  
    - Processed dataset  
    - All flows with extracted features  
    - Can be reused for analysis  
```
